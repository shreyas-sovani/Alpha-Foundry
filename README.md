# ğŸš€ DEX Arbitrage Intelligence Platform

Real-time arbitrage opportunity detection and monetization platform for EVM chains. Continuously monitors DEX pools, detects price discrepancies, and publishes encrypted datasets to **Lighthouse Storage** with automatic cleanup. Built for production deployment on **Railway** with enterprise-grade reliability.

## ğŸ¯ What It Does

- **ğŸ“Š Real-Time Monitoring**: Ingests swap events from Base, Ethereum, Polygon DEX pools every 5 minutes
- **ğŸ’ Arbitrage Detection**: Identifies profitable price deltas across DEX pairs using rolling 24h windows
- **ğŸ” Encrypted Storage**: Publishes datasets to Lighthouse with automatic old file cleanup (maintains single latest file)
- **ğŸ” Block Explorer Integration**: Every transaction links to Autoscout for deep inspection
- **ğŸ’¬ AI Agent Interface**: ASI:One chat protocol for conversational data access (future)
- **ğŸ’° Data Monetization**: Package and sell curated datasets via Lighthouse DataCoin (future)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸŒ Railway Platform                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Python Worker (apps/worker)                â”‚  â”‚
â”‚  â”‚  â€¢ Polls DEX events every 5 min via Blockscout MCP     â”‚  â”‚
â”‚  â”‚  â€¢ Transforms to JSONL with arbitrage detection        â”‚  â”‚
â”‚  â”‚  â€¢ Encrypts & uploads to Lighthouse                    â”‚  â”‚
â”‚  â”‚  â€¢ Auto-deletes old files (keeps only latest)          â”‚  â”‚
â”‚  â”‚  â€¢ Maintains state: checkpoints, deduplication         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼            â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Blockscoutâ”‚  â”‚Chainlinkâ”‚  â”‚ Lighthouse   â”‚
â”‚   MCP    â”‚  â”‚  Price  â”‚  â”‚   Storage    â”‚
â”‚  Server  â”‚  â”‚  Feeds  â”‚  â”‚ (Encrypted)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚            â”‚              â”‚
     â–¼            â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Base/ETH/Polygon Mainnet (RPC)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Production Features:**
- âœ… **Auto-Cleanup**: Maintains only 1 file on Lighthouse (deletes old uploads automatically)
- âœ… **Rolling Window**: 24-hour price tracking for accurate arbitrage detection
- âœ… **State Persistence**: Checkpoints, deduplication, price buffers survive restarts
- âœ… **Dual API Failover**: Primary/fallback endpoint switching on errors
- âœ… **HTTP Health Endpoint**: `/health` for Railway monitoring
- âœ… **Multi-Chain**: Base, Ethereum, Polygon support

## ğŸš€ Quick Start (Railway Deployment)

### Prerequisites
- Railway account ([railway.app](https://railway.app))
- Lighthouse API key ([files.lighthouse.storage](https://files.lighthouse.storage))
- Blockscout API keys for Base, Ethereum, Polygon
- Chainlink price feed contracts (optional, uses fallback if not set)

### Deploy to Railway

1. **Connect Repository**
   ```bash
   railway link
   ```

2. **Set Environment Variables** (in Railway dashboard or CLI)
   ```bash
   # Core Configuration
   BLOCKSCOUT_BASE_URL=https://base.blockscout.com
   BLOCKSCOUT_BASE_API_KEY=your_base_key
   BLOCKSCOUT_ETH_URL=https://eth.blockscout.com
   BLOCKSCOUT_ETH_API_KEY=your_eth_key
   BLOCKSCOUT_POLYGON_URL=https://polygon.blockscout.com
   BLOCKSCOUT_POLYGON_API_KEY=your_polygon_key
   
   # Lighthouse Storage (auto-cleanup enabled)
   LIGHTHOUSE_API_KEY=your_lighthouse_key
   
   # Optional: Chainlink Price Feeds (uses fallback if not set)
   CHAINLINK_ETH_USD=0x5f4eC3Df9cbd43714FE2740f5E3616155c5b8419
   CHAINLINK_USDC_USD=0x8fFfFfd4AfB6115b954Bd326cbe7B4BA576818f6
   ```

3. **Deploy**
   ```bash
   railway up
   ```

4. **Verify**
   - Check Railway logs for "âœ… Lighthouse upload successful"
   - Visit `/health` endpoint to confirm worker is running
   - Check Lighthouse dashboard - should see only 1 encrypted file (auto-cleanup working)

### Local Development

```bash
# Setup
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
pip install -r requirements.txt

# Configure
cp .env.example .env
# Edit .env with your API keys

# Run worker
python apps/worker/run.py

# Test HTTP endpoint
curl http://localhost:8787/health
```

## ğŸ“ Project Structure

```
af_hosted/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ worker/                    # ğŸ”„ Core ingestion worker
â”‚   â”‚   â”œâ”€â”€ run.py                 # Main entry point
â”‚   â”‚   â”œâ”€â”€ blockscout_client.py   # MCP server integration
â”‚   â”‚   â”œâ”€â”€ chainlink_price.py     # Price feed oracle
â”‚   â”‚   â”œâ”€â”€ transform.py           # JSONL transformation
â”‚   â”‚   â”œâ”€â”€ http_server.py         # Health endpoint
â”‚   â”‚   â”œâ”€â”€ lighthouse_cleanup.py  # Auto file cleanup (NEW)
â”‚   â”‚   â””â”€â”€ state/                 # Checkpoints & deduplication
â”‚   â””â”€â”€ hosted-agent/              # ğŸ’¬ Future: ASI:One chat interface
â”œâ”€â”€ infra/
â”‚   â””â”€â”€ autoscout/                 # ğŸ” Block explorer config
â”‚       â””â”€â”€ instance.json          # Explorer URLs
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_worker.sh              # Local development runner
â”‚   â””â”€â”€ verify_demo.py             # Demo data generator
â”œâ”€â”€ state/                         # ğŸ’¾ Persistent state (gitignored)
â”‚   â”œâ”€â”€ last_block.json
â”‚   â”œâ”€â”€ dedupe.json
â”‚   â”œâ”€â”€ price_buffer.json
â”‚   â””â”€â”€ block_ts.json
â”œâ”€â”€ nixpacks.toml                  # Railway build configuration
â”œâ”€â”€ Procfile                       # Railway startup command
â””â”€â”€ requirements.txt               # Python dependencies
```

## ğŸ”‘ Key Features

### âœ¨ Lighthouse Auto-Cleanup (NEW)
- **Automatic**: Runs after every successful upload
- **Efficient**: Deletes all old files, keeps only latest
- **Smart**: Uses Lighthouse CLI for reliable deletion
- **Fast**: Parallel deletion with progress tracking
- **Production-Ready**: Full error handling & logging

```python
# Happens automatically after each upload
cleanup_lighthouse_storage(
    api_key=LIGHTHOUSE_API_KEY,
    protected_cid="<latest_file_cid>",  # Don't delete this one
    dry_run=False                        # Delete for real
)
# Result: Only 1 file on Lighthouse âœ…
```

### ğŸ“Š Rolling Window Price Tracking
- 24-hour price history per token
- Accurate min/max/mean calculations
- Automatic expiry of old data
- Persistent across restarts

### ğŸ”„ Dual API Architecture
- Primary endpoint: `api.lighthouse.storage`
- Fallback endpoint: `upload.lighthouse.storage`
- Automatic failover on errors
- SDK upload with REST fallback

### ğŸ¯ Arbitrage Detection
- Real-time price delta calculation
- Multi-DEX comparison (Uniswap, PancakeSwap, SushiSwap)
- Profit opportunity highlighting
- Historical trend analysis

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Platform** | Railway | PaaS deployment with automatic builds |
| **Language** | Python 3.12 | Core worker implementation |
| **Build** | Nixpacks | Automatic dependency detection |
| **Storage** | Lighthouse | Encrypted decentralized file storage |
| **Blockchain** | Blockscout MCP | Chain data access layer |
| **Oracle** | Chainlink | Price feed verification |
| **Explorer** | Autoscout | Transaction inspection UI |

## ğŸ“Š Production Status

| Feature | Status | Details |
|---------|--------|---------|
| Worker Deployment | âœ… Live | Running on Railway (asia-southeast1) |
| Lighthouse Upload | âœ… Working | Encrypted JSONL every 5 minutes |
| Auto-Cleanup | âœ… Working | Maintains 1 file only |
| Rolling Window | âœ… Working | 24h price tracking |
| Multi-Chain | âœ… Working | Base + ETH + Polygon |
| HTTP Health | âœ… Working | `/health` endpoint on port 8787 |
| State Persistence | âœ… Working | Survives restarts |
| ASI:One Agent | ğŸš§ Future | Conversational interface planned |
| DataCoin Sales | ğŸš§ Future | Dataset monetization planned |

## ğŸ› Recent Fixes

### Lighthouse CLI Integration (Oct 2025)
- âœ… Fixed npm global bin PATH in Nix environment
- âœ… Added `[variables]` section to nixpacks.toml for runtime PATH
- âœ… Lighthouse CLI now available to Python subprocess calls
- âœ… Auto-cleanup working in production

### Import Bug Fix (Oct 2025)
- âœ… Fixed missing `from lighthouse_cleanup import cleanup_lighthouse_storage`
- âœ… Added proper error handling for CLI availability
- âœ… Added setup verification on startup

## ğŸ“š Documentation & Resources

### Platform Documentation
- [Railway Platform](https://docs.railway.app/)
- [Nixpacks Build System](https://nixpacks.com/)
- [Lighthouse Storage](https://docs.lighthouse.storage/)
- [Blockscout MCP Server](https://docs.blockscout.com/devs/mcp-server)

### Blockchain & DeFi
- [Base Network](https://docs.base.org/)
- [Chainlink Price Feeds](https://docs.chain.link/data-feeds)
- [Uniswap V3](https://docs.uniswap.org/contracts/v3/overview)

### Future Integration
- [Agentverse Platform](https://docs.agentverse.ai/)
- [ASI:One Protocol](https://docs.asi1.ai/)
- [Lighthouse DataCoin](https://docs.lighthouse.storage/lighthouse-1/how-to/create-a-datacoin)

## ğŸ¤ Contributing

This is a production system. For contributions:
1. Test locally first with `python apps/worker/run.py`
2. Verify Lighthouse upload works
3. Check auto-cleanup deletes old files
4. Ensure health endpoint responds
5. Submit PR with detailed testing notes

## ğŸ“„ License

Proprietary - All Rights Reserved
